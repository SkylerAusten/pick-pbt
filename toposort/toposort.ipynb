{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e37c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import deque, defaultdict\n",
    "import hypothesis as hp\n",
    "from hypothesis import strategies as st\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from typing import List, Optional, Set, Union\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from hypothesis_pick import (\n",
    "    find_disagreements,\n",
    "    find_stronger_weaker,\n",
    "    infer_implications,\n",
    ")\n",
    "\n",
    "# The assignment defines a valid input as a Directed Acyclic Graph (DAG)\n",
    "# represented by edges[cite: 196, 233].\n",
    "\n",
    "\n",
    "def topsort_implementation(edges: list[tuple[str, str]]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Implementation of topological sort based on assignment pseudocode.\n",
    "\n",
    "    Args:\n",
    "        edges: A list of (u, v) tuples representing directed edges.\n",
    "    Returns:\n",
    "        A list of vertices in topological order.\n",
    "    \"\"\"\n",
    "    # Build graph and in-degrees\n",
    "    adj = defaultdict(list)\n",
    "    in_degree = defaultdict(int)\n",
    "    nodes = set()\n",
    "\n",
    "    for u, v in edges:\n",
    "        adj[u].append(v)\n",
    "        nodes.add(u)\n",
    "        nodes.add(v)\n",
    "        in_degree[v] += 1\n",
    "        if u not in in_degree:\n",
    "            in_degree[u] = 0\n",
    "\n",
    "    # L = empty list to store ordering [cite: 204]\n",
    "    L = []\n",
    "\n",
    "    # S = set of vertices with no incoming edges [cite: 205]\n",
    "    # We sort S to make the output deterministic for testing, though not strictly required by alg.\n",
    "    S = sorted([n for n in nodes if in_degree[n] == 0])\n",
    "    queue = deque(S)\n",
    "\n",
    "    # while S is not empty [cite: 206]\n",
    "    while queue:\n",
    "        # u = vertex removed from S [cite: 207]\n",
    "        u = queue.popleft()\n",
    "        # append u to L [cite: 207]\n",
    "        L.append(u)\n",
    "\n",
    "        # for each vertex v where edge e=(u,v) in g [cite: 208]\n",
    "        for v in adj[u]:\n",
    "            # remove e from g (simulated by decrementing in-degree) [cite: 209]\n",
    "            in_degree[v] -= 1\n",
    "            # if v has no other incoming edges [cite: 210]\n",
    "            if in_degree[v] == 0:\n",
    "                # insert v in S [cite: 210]\n",
    "                queue.append(v)\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1556ae83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_diamond_graph (__main__.TestToposortImplementation.test_diamond_graph) ... ok\n",
      "test_disconnected_components (__main__.TestToposortImplementation.test_disconnected_components) ... ok\n",
      "test_empty_graph (__main__.TestToposortImplementation.test_empty_graph) ... ok\n",
      "test_multiple_sources_single_sink (__main__.TestToposortImplementation.test_multiple_sources_single_sink) ... ok\n",
      "test_single_edge (__main__.TestToposortImplementation.test_single_edge) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.006s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=5 errors=0 failures=0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit tests for topsort_implementation (run this cell)\n",
    "\n",
    "import unittest\n",
    "\n",
    "def _is_valid_toposort(edges: list[tuple[str, str]], order: list[str]) -> bool:\n",
    "\n",
    "    \"\"\"Checks that `order` is a valid topological ordering for `edges`.\"\"\"\n",
    "\n",
    "    nodes = {u for u, _ in edges} | {v for _, v in edges}\n",
    "\n",
    "    if not nodes:\n",
    "\n",
    "        return order == []\n",
    "\n",
    "\n",
    "\n",
    "    if set(order) != nodes or len(order) != len(nodes):\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "    pos = {node: i for i, node in enumerate(order)}\n",
    "\n",
    "    return all(pos[u] < pos[v] for u, v in edges)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TestToposortImplementation(unittest.TestCase):\n",
    "\n",
    "    def test_empty_graph(self) -> None:\n",
    "\n",
    "        self.assertEqual(topsort_implementation([]), [])\n",
    "\n",
    "\n",
    "\n",
    "    def test_single_edge(self) -> None:\n",
    "\n",
    "        edges = [(\"A\", \"B\")]\n",
    "\n",
    "        order = topsort_implementation(edges)\n",
    "\n",
    "        self.assertEqual(order, [\"A\", \"B\"])  # deterministic for this input\n",
    "\n",
    "        self.assertTrue(_is_valid_toposort(edges, order))\n",
    "\n",
    "\n",
    "\n",
    "    def test_diamond_graph(self) -> None:\n",
    "\n",
    "        # A before B and C; both before D.\n",
    "\n",
    "        edges = [(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"D\"), (\"C\", \"D\")]\n",
    "\n",
    "        order = topsort_implementation(edges)\n",
    "\n",
    "        self.assertEqual(order, [\"A\", \"B\", \"C\", \"D\"])  # deterministic given edge order\n",
    "\n",
    "        self.assertTrue(_is_valid_toposort(edges, order))\n",
    "\n",
    "\n",
    "\n",
    "    def test_disconnected_components(self) -> None:\n",
    "\n",
    "        edges = [(\"A\", \"B\"), (\"C\", \"D\")]\n",
    "\n",
    "        order = topsort_implementation(edges)\n",
    "\n",
    "        self.assertEqual(order, [\"A\", \"C\", \"B\", \"D\"])  # deterministic given current algorithm\n",
    "\n",
    "        self.assertTrue(_is_valid_toposort(edges, order))\n",
    "\n",
    "\n",
    "\n",
    "    def test_multiple_sources_single_sink(self) -> None:\n",
    "\n",
    "        edges = [(\"A\", \"D\"), (\"B\", \"D\"), (\"C\", \"D\")]\n",
    "\n",
    "        order = topsort_implementation(edges)\n",
    "\n",
    "        self.assertTrue(_is_valid_toposort(edges, order))\n",
    "\n",
    "        self.assertEqual(order[-1], \"D\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "suite = unittest.defaultTestLoader.loadTestsFromTestCase(TestToposortImplementation)\n",
    "\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "\n",
    "runner.run(suite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94529f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy to generate a DAG and a candidate result list\n",
    "@st.composite\n",
    "def graph_and_candidate_strategy(draw):\n",
    "    # 1. Generate a valid DAG\n",
    "    # We do this by generating nodes and only allowing edges from lower index to higher index\n",
    "    # to guarantee acyclicity.\n",
    "    nodes = draw(\n",
    "        st.lists(\n",
    "            st.text(alphabet=\"ABCDE\", min_size=1, max_size=2),\n",
    "            min_size=2,\n",
    "            max_size=6,\n",
    "            unique=True,\n",
    "        )\n",
    "    )\n",
    "    nodes = sorted(nodes)\n",
    "\n",
    "    edges = []\n",
    "    # Create random forward edges\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i + 1, len(nodes)):\n",
    "            if draw(st.booleans()):\n",
    "                edges.append((nodes[i], nodes[j]))\n",
    "\n",
    "    # 2. Determine the \"Ground Truth\" using our implementation\n",
    "    valid_sort = topsort_implementation(edges)\n",
    "\n",
    "    # 3. Create a candidate output that might be wrong to trigger predicate disagreements\n",
    "    # We mix: Valid sorts, Alphabetical sorts, and Random shuffles.\n",
    "    case_type = draw(st.sampled_from([\"valid\", \"lexical\", \"shuffled\", \"missing_node\"]))\n",
    "\n",
    "    if case_type == \"valid\":\n",
    "        candidate = valid_sort\n",
    "    elif case_type == \"lexical\":\n",
    "        candidate = sorted(nodes)\n",
    "    elif case_type == \"shuffled\":\n",
    "        candidate = valid_sort[:]  # copy\n",
    "        # We need a deterministic shuffle for reproducibility in PBT,\n",
    "        # but for this specific setup, st.permutations is cleaner:\n",
    "        candidate = draw(st.permutations(valid_sort))\n",
    "    else:  # missing_node\n",
    "        candidate = valid_sort[:-1] if valid_sort else []\n",
    "\n",
    "    # The input to our predicates is the Tuple(Edges, Candidate_List)\n",
    "    return (edges, candidate)\n",
    "\n",
    "\n",
    "# Update the main strategy variable for the PICK system\n",
    "strategy = graph_and_candidate_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b5bb954",
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphInput = tuple[List[tuple[str, str]], List[str]]\n",
    "\n",
    "\n",
    "def p1_is_valid_toposort(x: GraphInput) -> bool:\n",
    "    \"\"\"True if candidate respects all edge dependencies and contains all nodes.\"\"\"\n",
    "    edges, candidate = x\n",
    "\n",
    "    # Check 1: Are all nodes present?\n",
    "    graph_nodes = set(u for u, v in edges) | set(v for u, v in edges)\n",
    "    if set(candidate) != graph_nodes or len(candidate) != len(graph_nodes):\n",
    "        return False\n",
    "\n",
    "    # Check 2: Are edge constraints respected? (u must appear before v) [cite: 286]\n",
    "    # Create a map of node -> index for O(1) lookups\n",
    "    position = {node: i for i, node in enumerate(candidate)}\n",
    "\n",
    "    for u, v in edges:\n",
    "        # If u or v isn't in candidate, it fails (caught by Check 1 usually, but safe to check)\n",
    "        if u not in position or v not in position:\n",
    "            return False\n",
    "        if position[u] > position[v]:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def p2_is_permutation(x: GraphInput) -> bool:\n",
    "    \"\"\"True if candidate contains exactly the set of nodes in the graph (ignores order).\"\"\"\n",
    "    edges, candidate = x\n",
    "    graph_nodes = set(u for u, v in edges) | set(v for u, v in edges)\n",
    "    return set(candidate) == graph_nodes and len(candidate) == len(graph_nodes)\n",
    "\n",
    "\n",
    "def p3_is_lexical(x: GraphInput) -> bool:\n",
    "    \"\"\"True if candidate is sorted alphabetically (ignores graph structure).\"\"\"\n",
    "    edges, candidate = x\n",
    "    # Just checks if the list is sorted\n",
    "    return candidate == sorted(candidate) and len(candidate) > 0\n",
    "\n",
    "\n",
    "def p4_valid_source_sink(x: GraphInput) -> bool:\n",
    "    \"\"\"True if the first element is a valid source and last is a valid sink.\"\"\"\n",
    "    edges, candidate = x\n",
    "    if not candidate:\n",
    "        return False\n",
    "\n",
    "    # Build degrees\n",
    "    in_degree = defaultdict(int)\n",
    "    out_degree = defaultdict(int)\n",
    "    nodes = set()\n",
    "    for u, v in edges:\n",
    "        in_degree[v] += 1\n",
    "        out_degree[u] += 1\n",
    "        nodes.add(u)\n",
    "        nodes.add(v)\n",
    "\n",
    "    first = candidate[0]\n",
    "    last = candidate[-1]\n",
    "\n",
    "    # First node must have 0 in-degree (Source) [cite: 295]\n",
    "    is_source = in_degree[first] == 0\n",
    "    # Last node must have 0 out-degree (Sink)\n",
    "    is_sink = out_degree[last] == 0\n",
    "\n",
    "    return is_source and is_sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5cf154",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICATES = [\n",
    "    p1_is_valid_toposort,\n",
    "    p2_is_permutation,\n",
    "    p3_is_lexical,\n",
    "    p4_valid_source_sink,\n",
    "]\n",
    "PREDICATE_NAMES = [\n",
    "    \"Valid Toposort\",\n",
    "    \"Is Permutation\",\n",
    "    \"Is Alphabetical\",\n",
    "    \"Valid Source/Sink\",\n",
    "]\n",
    "\n",
    "NAME_TO_PREDICATE = dict(zip(PREDICATE_NAMES, PREDICATES))\n",
    "\n",
    "assert len(PREDICATES) == len(PREDICATE_NAMES)\n",
    "\n",
    "# Reset the cache for the new problem domain\n",
    "combination_examples = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4485c36",
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedHealthCheck",
     "evalue": "Input generation is slow: Hypothesis only generated 2 valid inputs after 4.72 seconds.\n\n      count | fraction |    slowest draws (seconds)\n  x |    2  |    100%  |      --      --      --      --   4.723\n\nThis could be for a few reasons:\n1. This strategy could be generating too much data per input. Try decreasing the amount of data generated, for example by decreasing the minimum size of collection strategies like st.lists().\n2. Some other expensive computation could be running during input generation. For example, if @st.composite or st.data() is interspersed with an expensive computation, HealthCheck.too_slow is likely to trigger. If this computation is unrelated to input generation, move it elsewhere. Otherwise, try making it more efficient, or disable this health check if that is not possible.\n\nIf you expect input generation to take this long, you can disable this health check with @settings(suppress_health_check=[HealthCheck.too_slow]). See https://hypothesis.readthedocs.io/en/latest/reference/api.html#hypothesis.HealthCheck for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFailedHealthCheck\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m impl = \u001b[43minfer_implications\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpredicates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPREDICATES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpredicate_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPREDICATE_NAMES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclassify_relationship\u001b[39m(name_a: \u001b[38;5;28mstr\u001b[39m, name_b: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m impl.equivalent(name_a, name_b):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\me\\Desktop\\GitHub Repos\\pick-pbt\\hypothesis_pick\\core.py:251\u001b[39m, in \u001b[36minfer_implications\u001b[39m\u001b[34m(predicates, strategy, max_examples, predicate_names, collect_counterexamples, max_counterexamples)\u001b[39m\n\u001b[32m    248\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(counterexamples[key]) < max_counterexamples:\n\u001b[32m    249\u001b[39m                             counterexamples[key].append(x)\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[43mcheck_implications\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# Build the result\u001b[39;00m\n\u001b[32m    254\u001b[39m result = ImplicationResult(\n\u001b[32m    255\u001b[39m     implications=potential_implications,\n\u001b[32m    256\u001b[39m     counterexamples=counterexamples \u001b[38;5;28;01mif\u001b[39;00m collect_counterexamples \u001b[38;5;28;01melse\u001b[39;00m {},\n\u001b[32m    257\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\me\\Desktop\\GitHub Repos\\pick-pbt\\hypothesis_pick\\core.py:226\u001b[39m, in \u001b[36minfer_implications.<locals>.check_implications\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    219\u001b[39m potential_implications: Dict[\u001b[38;5;28mstr\u001b[39m, Set[\u001b[38;5;28mstr\u001b[39m]] = {\n\u001b[32m    220\u001b[39m     name: \u001b[38;5;28mset\u001b[39m(n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m names \u001b[38;5;28;01mif\u001b[39;00m n != name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names\n\u001b[32m    221\u001b[39m }\n\u001b[32m    223\u001b[39m counterexamples: Dict[Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m], List[Any]] = {}\n\u001b[32m    225\u001b[39m \u001b[38;5;129m@given\u001b[39m(strategy)\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m \u001b[38;5;129m@settings\u001b[39m(\n\u001b[32m    227\u001b[39m     max_examples=max_examples,\n\u001b[32m    228\u001b[39m     database=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    229\u001b[39m     verbosity=Verbosity.quiet,\n\u001b[32m    230\u001b[39m     phases=[Phase.generate],\n\u001b[32m    231\u001b[39m )\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_implications\u001b[39m(x: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     result = _evaluate_predicates(pred_dict, x)\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# For each predicate p_i that is True\u001b[39;00m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\me\\Desktop\\GitHub Repos\\pick-pbt\\.venv\\Lib\\site-packages\\hypothesis\\internal\\healthcheck.py:21\u001b[39m, in \u001b[36mfail_health_check\u001b[39m\u001b[34m(settings, message, label)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m settings.suppress_health_check:\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m FailedHealthCheck(message)\n",
      "\u001b[31mFailedHealthCheck\u001b[39m: Input generation is slow: Hypothesis only generated 2 valid inputs after 4.72 seconds.\n\n      count | fraction |    slowest draws (seconds)\n  x |    2  |    100%  |      --      --      --      --   4.723\n\nThis could be for a few reasons:\n1. This strategy could be generating too much data per input. Try decreasing the amount of data generated, for example by decreasing the minimum size of collection strategies like st.lists().\n2. Some other expensive computation could be running during input generation. For example, if @st.composite or st.data() is interspersed with an expensive computation, HealthCheck.too_slow is likely to trigger. If this computation is unrelated to input generation, move it elsewhere. Otherwise, try making it more efficient, or disable this health check if that is not possible.\n\nIf you expect input generation to take this long, you can disable this health check with @settings(suppress_health_check=[HealthCheck.too_slow]). See https://hypothesis.readthedocs.io/en/latest/reference/api.html#hypothesis.HealthCheck for details."
     ]
    }
   ],
   "source": [
    "impl = infer_implications(\n",
    "    predicates=PREDICATES,\n",
    "    strategy=strategy,\n",
    "    max_examples=1_000,\n",
    "    predicate_names=PREDICATE_NAMES,\n",
    ")\n",
    "\n",
    "\n",
    "def classify_relationship(name_a: str, name_b: str) -> str:\n",
    "    if impl.equivalent(name_a, name_b):\n",
    "        return \"equivalent\"\n",
    "    if impl.implies(name_a, name_b):\n",
    "        return \"subset\"\n",
    "    if impl.implies(name_b, name_a):\n",
    "        return \"superset\"\n",
    "    predicate_a = NAME_TO_PREDICATE[name_a]\n",
    "    predicate_b = NAME_TO_PREDICATE[name_b]\n",
    "    for candidate in range(0, 2_000):\n",
    "        if predicate_a(candidate) and predicate_b(candidate):\n",
    "            return \"overlap\"\n",
    "    return \"disjoint\"\n",
    "\n",
    "\n",
    "def build_pair_entry(name_a: str, name_b: str) -> dict:\n",
    "    return {\n",
    "        \"relation\": classify_relationship(name_a, name_b),\n",
    "    }\n",
    "\n",
    "\n",
    "pair_relationships = {\n",
    "    (name_a, name_b): build_pair_entry(name_a, name_b)\n",
    "    for i, name_a in enumerate(PREDICATE_NAMES)\n",
    "    for name_b in PREDICATE_NAMES[i + 1 :]\n",
    "}\n",
    "\n",
    "combination_examples = defaultdict(list)\n",
    "\n",
    "\n",
    "def record_combination(value: int) -> None:\n",
    "    key = tuple(bool(NAME_TO_PREDICATE[name](value)) for name in PREDICATE_NAMES)\n",
    "    bucket = combination_examples[key]\n",
    "    if len(bucket) < MAX_EXAMPLES_PER_COMBINATION and value not in bucket:\n",
    "        bucket.append(value)\n",
    "\n",
    "\n",
    "def combinations_saturated() -> bool:\n",
    "    if not combination_examples:\n",
    "        return False\n",
    "    return all(\n",
    "        len(bucket) >= MAX_EXAMPLES_PER_COMBINATION\n",
    "        for bucket in combination_examples.values()\n",
    "    )\n",
    "\n",
    "\n",
    "# I believe this is doing duplicate work to Sid's library,\n",
    "# but I couldn't get its example cacheing to work, so reimplementing here.\n",
    "# TODO: Fix that and use it instead.\n",
    "def populate_combination_examples(max_draws: int = 5_000) -> None:\n",
    "    seen_values = set()\n",
    "    draws = 0\n",
    "    while draws < max_draws:\n",
    "        value = strategy.example()\n",
    "        draws += 1\n",
    "        if value in seen_values:\n",
    "            continue\n",
    "        seen_values.add(value)\n",
    "        record_combination(value)\n",
    "        if combinations_saturated():\n",
    "            break\n",
    "\n",
    "\n",
    "populate_combination_examples()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
