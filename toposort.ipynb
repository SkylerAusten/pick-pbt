{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e37c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import deque, defaultdict\n",
    "import hypothesis as hp\n",
    "from hypothesis import strategies as st\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from typing import List, Optional, Set, Union\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from hypothesis_pick import (\n",
    "    find_disagreements,\n",
    "    find_stronger_weaker,\n",
    "    infer_implications,\n",
    ")\n",
    "\n",
    "# The assignment defines a valid input as a Directed Acyclic Graph (DAG)\n",
    "# represented by edges[cite: 196, 233].\n",
    "\n",
    "\n",
    "def topsort_implementation(edges: list[tuple[str, str]]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Implementation of topological sort based on assignment pseudocode.\n",
    "\n",
    "    Args:\n",
    "        edges: A list of (u, v) tuples representing directed edges.\n",
    "    Returns:\n",
    "        A list of vertices in topological order.\n",
    "    \"\"\"\n",
    "    # Build graph and in-degrees\n",
    "    adj = defaultdict(list)\n",
    "    in_degree = defaultdict(int)\n",
    "    nodes = set()\n",
    "\n",
    "    for u, v in edges:\n",
    "        adj[u].append(v)\n",
    "        nodes.add(u)\n",
    "        nodes.add(v)\n",
    "        in_degree[v] += 1\n",
    "        if u not in in_degree:\n",
    "            in_degree[u] = 0\n",
    "\n",
    "    # L = empty list to store ordering [cite: 204]\n",
    "    L = []\n",
    "\n",
    "    # S = set of vertices with no incoming edges [cite: 205]\n",
    "    # We sort S to make the output deterministic for testing, though not strictly required by alg.\n",
    "    S = sorted([n for n in nodes if in_degree[n] == 0])\n",
    "    queue = deque(S)\n",
    "\n",
    "    # while S is not empty [cite: 206]\n",
    "    while queue:\n",
    "        # u = vertex removed from S [cite: 207]\n",
    "        u = queue.popleft()\n",
    "        # append u to L [cite: 207]\n",
    "        L.append(u)\n",
    "\n",
    "        # for each vertex v where edge e=(u,v) in g [cite: 208]\n",
    "        for v in adj[u]:\n",
    "            # remove e from g (simulated by decrementing in-degree) [cite: 209]\n",
    "            in_degree[v] -= 1\n",
    "            # if v has no other incoming edges [cite: 210]\n",
    "            if in_degree[v] == 0:\n",
    "                # insert v in S [cite: 210]\n",
    "                queue.append(v)\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94529f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy to generate a DAG and a candidate result list\n",
    "@st.composite\n",
    "def graph_and_candidate_strategy(draw):\n",
    "    # 1. Generate a valid DAG\n",
    "    # We do this by generating nodes and only allowing edges from lower index to higher index\n",
    "    # to guarantee acyclicity.\n",
    "    nodes = draw(\n",
    "        st.lists(\n",
    "            st.text(alphabet=\"ABCDE\", min_size=1, max_size=2),\n",
    "            min_size=2,\n",
    "            max_size=6,\n",
    "            unique=True,\n",
    "        )\n",
    "    )\n",
    "    nodes = sorted(nodes)\n",
    "\n",
    "    edges = []\n",
    "    # Create random forward edges\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i + 1, len(nodes)):\n",
    "            if draw(st.booleans()):\n",
    "                edges.append((nodes[i], nodes[j]))\n",
    "\n",
    "    # 2. Determine the \"Ground Truth\" using our implementation\n",
    "    valid_sort = topsort_implementation(edges)\n",
    "\n",
    "    # 3. Create a candidate output that might be wrong to trigger predicate disagreements\n",
    "    # We mix: Valid sorts, Alphabetical sorts, and Random shuffles.\n",
    "    case_type = draw(st.sampled_from([\"valid\", \"lexical\", \"shuffled\", \"missing_node\"]))\n",
    "\n",
    "    if case_type == \"valid\":\n",
    "        candidate = valid_sort\n",
    "    elif case_type == \"lexical\":\n",
    "        candidate = sorted(nodes)\n",
    "    elif case_type == \"shuffled\":\n",
    "        candidate = valid_sort[:]  # copy\n",
    "        # We need a deterministic shuffle for reproducibility in PBT,\n",
    "        # but for this specific setup, st.permutations is cleaner:\n",
    "        candidate = draw(st.permutations(valid_sort))\n",
    "    else:  # missing_node\n",
    "        candidate = valid_sort[:-1] if valid_sort else []\n",
    "\n",
    "    # The input to our predicates is the Tuple(Edges, Candidate_List)\n",
    "    return (edges, candidate)\n",
    "\n",
    "\n",
    "# Update the main strategy variable for the PICK system\n",
    "strategy = graph_and_candidate_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b5bb954",
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphInput = tuple[List[tuple[str, str]], List[str]]\n",
    "\n",
    "\n",
    "def p1_is_valid_toposort(x: GraphInput) -> bool:\n",
    "    \"\"\"True if candidate respects all edge dependencies and contains all nodes.\"\"\"\n",
    "    edges, candidate = x\n",
    "\n",
    "    # Check 1: Are all nodes present?\n",
    "    graph_nodes = set(u for u, v in edges) | set(v for u, v in edges)\n",
    "    if set(candidate) != graph_nodes or len(candidate) != len(graph_nodes):\n",
    "        return False\n",
    "\n",
    "    # Check 2: Are edge constraints respected? (u must appear before v) [cite: 286]\n",
    "    # Create a map of node -> index for O(1) lookups\n",
    "    position = {node: i for i, node in enumerate(candidate)}\n",
    "\n",
    "    for u, v in edges:\n",
    "        # If u or v isn't in candidate, it fails (caught by Check 1 usually, but safe to check)\n",
    "        if u not in position or v not in position:\n",
    "            return False\n",
    "        if position[u] > position[v]:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def p2_is_permutation(x: GraphInput) -> bool:\n",
    "    \"\"\"True if candidate contains exactly the set of nodes in the graph (ignores order).\"\"\"\n",
    "    edges, candidate = x\n",
    "    graph_nodes = set(u for u, v in edges) | set(v for u, v in edges)\n",
    "    return set(candidate) == graph_nodes and len(candidate) == len(graph_nodes)\n",
    "\n",
    "\n",
    "def p3_is_lexical(x: GraphInput) -> bool:\n",
    "    \"\"\"True if candidate is sorted alphabetically (ignores graph structure).\"\"\"\n",
    "    edges, candidate = x\n",
    "    # Just checks if the list is sorted\n",
    "    return candidate == sorted(candidate) and len(candidate) > 0\n",
    "\n",
    "\n",
    "def p4_valid_source_sink(x: GraphInput) -> bool:\n",
    "    \"\"\"True if the first element is a valid source and last is a valid sink.\"\"\"\n",
    "    edges, candidate = x\n",
    "    if not candidate:\n",
    "        return False\n",
    "\n",
    "    # Build degrees\n",
    "    in_degree = defaultdict(int)\n",
    "    out_degree = defaultdict(int)\n",
    "    nodes = set()\n",
    "    for u, v in edges:\n",
    "        in_degree[v] += 1\n",
    "        out_degree[u] += 1\n",
    "        nodes.add(u)\n",
    "        nodes.add(v)\n",
    "\n",
    "    first = candidate[0]\n",
    "    last = candidate[-1]\n",
    "\n",
    "    # First node must have 0 in-degree (Source) [cite: 295]\n",
    "    is_source = in_degree[first] == 0\n",
    "    # Last node must have 0 out-degree (Sink)\n",
    "    is_sink = out_degree[last] == 0\n",
    "\n",
    "    return is_source and is_sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b5cf154",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICATES = [\n",
    "    p1_is_valid_toposort,\n",
    "    p2_is_permutation,\n",
    "    p3_is_lexical,\n",
    "    p4_valid_source_sink,\n",
    "]\n",
    "PREDICATE_NAMES = [\n",
    "    \"Valid Toposort\",\n",
    "    \"Is Permutation\",\n",
    "    \"Is Alphabetical\",\n",
    "    \"Valid Source/Sink\",\n",
    "]\n",
    "\n",
    "NAME_TO_PREDICATE = dict(zip(PREDICATE_NAMES, PREDICATES))\n",
    "\n",
    "assert len(PREDICATES) == len(PREDICATE_NAMES)\n",
    "\n",
    "# Reset the cache for the new problem domain\n",
    "combination_examples = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4485c36",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_pair_entry\u001b[39m(name_a: \u001b[38;5;28mstr\u001b[39m, name_b: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     26\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrelation\u001b[39m\u001b[33m\"\u001b[39m: classify_relationship(name_a, name_b),\n\u001b[32m     27\u001b[39m     }\n\u001b[32m     30\u001b[39m pair_relationships = {\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     (name_a, name_b): \u001b[43mbuild_pair_entry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, name_a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(PREDICATE_NAMES)\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name_b \u001b[38;5;129;01min\u001b[39;00m PREDICATE_NAMES[i + \u001b[32m1\u001b[39m :]\n\u001b[32m     34\u001b[39m }\n\u001b[32m     36\u001b[39m combination_examples = defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrecord_combination\u001b[39m(value: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mbuild_pair_entry\u001b[39m\u001b[34m(name_a, name_b)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_pair_entry\u001b[39m(name_a: \u001b[38;5;28mstr\u001b[39m, name_b: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrelation\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mclassify_relationship\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_b\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     27\u001b[39m     }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mclassify_relationship\u001b[39m\u001b[34m(name_a, name_b)\u001b[39m\n\u001b[32m     17\u001b[39m predicate_b = NAME_TO_PREDICATE[name_b]\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m candidate \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m2_000\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpredicate_a\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m predicate_b(candidate):\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33moverlap\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisjoint\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mp1_is_valid_toposort\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mp1_is_valid_toposort\u001b[39m(x: GraphInput) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"True if candidate respects all edge dependencies and contains all nodes.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     edges, candidate = x\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Check 1: Are all nodes present?\u001b[39;00m\n\u001b[32m      9\u001b[39m     graph_nodes = \u001b[38;5;28mset\u001b[39m(u \u001b[38;5;28;01mfor\u001b[39;00m u, v \u001b[38;5;129;01min\u001b[39;00m edges) | \u001b[38;5;28mset\u001b[39m(v \u001b[38;5;28;01mfor\u001b[39;00m u, v \u001b[38;5;129;01min\u001b[39;00m edges)\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "impl = infer_implications(\n",
    "    predicates=PREDICATES,\n",
    "    strategy=strategy,\n",
    "    max_examples=1_000,\n",
    "    predicate_names=PREDICATE_NAMES,\n",
    ")\n",
    "\n",
    "\n",
    "def classify_relationship(name_a: str, name_b: str) -> str:\n",
    "    if impl.equivalent(name_a, name_b):\n",
    "        return \"equivalent\"\n",
    "    if impl.implies(name_a, name_b):\n",
    "        return \"subset\"\n",
    "    if impl.implies(name_b, name_a):\n",
    "        return \"superset\"\n",
    "    predicate_a = NAME_TO_PREDICATE[name_a]\n",
    "    predicate_b = NAME_TO_PREDICATE[name_b]\n",
    "    for candidate in range(0, 2_000):\n",
    "        if predicate_a(candidate) and predicate_b(candidate):\n",
    "            return \"overlap\"\n",
    "    return \"disjoint\"\n",
    "\n",
    "\n",
    "def build_pair_entry(name_a: str, name_b: str) -> dict:\n",
    "    return {\n",
    "        \"relation\": classify_relationship(name_a, name_b),\n",
    "    }\n",
    "\n",
    "\n",
    "pair_relationships = {\n",
    "    (name_a, name_b): build_pair_entry(name_a, name_b)\n",
    "    for i, name_a in enumerate(PREDICATE_NAMES)\n",
    "    for name_b in PREDICATE_NAMES[i + 1 :]\n",
    "}\n",
    "\n",
    "combination_examples = defaultdict(list)\n",
    "\n",
    "\n",
    "def record_combination(value: int) -> None:\n",
    "    key = tuple(bool(NAME_TO_PREDICATE[name](value)) for name in PREDICATE_NAMES)\n",
    "    bucket = combination_examples[key]\n",
    "    if len(bucket) < MAX_EXAMPLES_PER_COMBINATION and value not in bucket:\n",
    "        bucket.append(value)\n",
    "\n",
    "\n",
    "def combinations_saturated() -> bool:\n",
    "    if not combination_examples:\n",
    "        return False\n",
    "    return all(\n",
    "        len(bucket) >= MAX_EXAMPLES_PER_COMBINATION\n",
    "        for bucket in combination_examples.values()\n",
    "    )\n",
    "\n",
    "\n",
    "# I believe this is doing duplicate work to Sid's library,\n",
    "# but I couldn't get its example cacheing to work, so reimplementing here.\n",
    "# TODO: Fix that and use it instead.\n",
    "def populate_combination_examples(max_draws: int = 5_000) -> None:\n",
    "    seen_values = set()\n",
    "    draws = 0\n",
    "    while draws < max_draws:\n",
    "        value = strategy.example()\n",
    "        draws += 1\n",
    "        if value in seen_values:\n",
    "            continue\n",
    "        seen_values.add(value)\n",
    "        record_combination(value)\n",
    "        if combinations_saturated():\n",
    "            break\n",
    "\n",
    "\n",
    "populate_combination_examples()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
